{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv( \"../data/casas.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare( df ):\n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    enc = preprocessing.OneHotEncoder(handle_unknown='ignore')\n",
    "    df[\"Ages\"] = le.fit_transform( df[\"Ages\"] )\n",
    "    df1 = pd.get_dummies( df[\"Ages\"] )\n",
    "    \n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    enc = preprocessing.OneHotEncoder(handle_unknown='ignore')\n",
    "    df[\"Condition\"] = le.fit_transform( df[\"Condition\"] )\n",
    "    df2 = pd.get_dummies( df[\"Condition\"] )\n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    enc = preprocessing.OneHotEncoder(handle_unknown='ignore')\n",
    "    df[\"Location3\"] = le.fit_transform( df[\"Location3\"] )\n",
    "    df3 = pd.get_dummies( df[\"Location3\"])\n",
    "    \n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    enc = preprocessing.OneHotEncoder(handle_unknown='ignore')\n",
    "    df[\"FloorId\"] = le.fit_transform( df[\"FloorId\"] )\n",
    "    df4 = pd.get_dummies( df[\"FloorId\"])\n",
    "    \n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    enc = preprocessing.OneHotEncoder(handle_unknown='ignore')\n",
    "    df[\"Stratum\"] = le.fit_transform( df[\"Stratum\"] )\n",
    "    df5 = pd.get_dummies( df[\"Stratum\"])\n",
    "    \n",
    "    \n",
    "    ls = [ df1 , df2 , df3 , df4 , df5 , df[\"Area\"] , df[\"Baths\"]  , df[\"Rooms\"] ]\n",
    "    \n",
    "    X = pd.concat( ls , axis = 1 )\n",
    "    y = np.log( df[\"FormatedPrice\"]/1e6 )\n",
    "    \n",
    "    return X.values , y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X , y = prepare( df )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "num_leaves = 15\n",
    "min_data_in_leaf = 2000\n",
    "feature_fraction = 0.8\n",
    "num_boost_round = 1000\n",
    "params = {\"objective\": \"regression\",\n",
    "          \"boosting_type\": \"gbdt\",\n",
    "          \"learning_rate\": learning_rate,\n",
    "          \"metric\":[\"mse\"] , \n",
    "          \"num_leaves\": num_leaves,\n",
    "           \"max_bin\": 256,\n",
    "          \"feature_fraction\": feature_fraction,\n",
    "          \"verbosity\": 0,\n",
    "          \"drop_rate\": 0.1,\n",
    "          \"is_unbalance\": False,\n",
    "          \"max_drop\": 50,\n",
    "          \"min_child_samples\": 10,\n",
    "          \"min_child_weight\": 150,\n",
    "          \"min_split_gain\": 0,\n",
    "          \"subsample\": 0.9 , \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 0.112072\n",
      "[200]\tvalid_0's l2: 0.109472\n",
      "[300]\tvalid_0's l2: 0.109834\n",
      "Early stopping, best iteration is:\n",
      "[207]\tvalid_0's l2: 0.109263\n",
      "0.10926253215873803\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 0.205625\n",
      "[200]\tvalid_0's l2: 0.203557\n",
      "Early stopping, best iteration is:\n",
      "[199]\tvalid_0's l2: 0.203544\n",
      "0.20354428086017234\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 0.0965915\n",
      "[200]\tvalid_0's l2: 0.095435\n",
      "Early stopping, best iteration is:\n",
      "[165]\tvalid_0's l2: 0.0953133\n",
      "0.09531332351519167\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 0.146169\n",
      "[200]\tvalid_0's l2: 0.143836\n",
      "[300]\tvalid_0's l2: 0.143577\n",
      "Early stopping, best iteration is:\n",
      "[241]\tvalid_0's l2: 0.143399\n",
      "0.1433988643482287\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 0.164236\n",
      "[200]\tvalid_0's l2: 0.160596\n",
      "[300]\tvalid_0's l2: 0.160045\n",
      "[400]\tvalid_0's l2: 0.160726\n",
      "Early stopping, best iteration is:\n",
      "[341]\tvalid_0's l2: 0.15975\n",
      "0.15974951926208308\n",
      "cv score:\n",
      "0.1422537040288828\n",
      "current score: 0.1422537040288828 1\n",
      "[0.10926253215873803, 0.20354428086017234, 0.09531332351519167, 0.1433988643482287, 0.15974951926208308]\n",
      "[207, 199, 165, 241, 341] 230.6\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 0.112659\n",
      "[200]\tvalid_0's l2: 0.11028\n",
      "[300]\tvalid_0's l2: 0.110086\n",
      "Early stopping, best iteration is:\n",
      "[239]\tvalid_0's l2: 0.109597\n",
      "0.10959742070246124\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 0.207386\n",
      "[200]\tvalid_0's l2: 0.20443\n",
      "[300]\tvalid_0's l2: 0.204971\n",
      "Early stopping, best iteration is:\n",
      "[203]\tvalid_0's l2: 0.204245\n",
      "0.20424536478685104\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 0.09722\n",
      "[200]\tvalid_0's l2: 0.0956171\n",
      "Early stopping, best iteration is:\n",
      "[199]\tvalid_0's l2: 0.0956062\n",
      "0.09560617873807767\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 0.144517\n",
      "[200]\tvalid_0's l2: 0.142614\n",
      "[300]\tvalid_0's l2: 0.143332\n",
      "Early stopping, best iteration is:\n",
      "[255]\tvalid_0's l2: 0.142537\n",
      "0.14253709020129726\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 0.162193\n",
      "[200]\tvalid_0's l2: 0.159606\n",
      "[300]\tvalid_0's l2: 0.157988\n"
     ]
    }
   ],
   "source": [
    "NFOLDS = 5\n",
    "kfold = KFold(n_splits=NFOLDS, shuffle=True, random_state=218)\n",
    "\n",
    "\n",
    "final_cv_train = np.zeros(len(y))\n",
    "x_score = []\n",
    "\n",
    "for s in range(16):\n",
    "    cv_train = np.zeros(len(y))\n",
    "    params['seed'] = s\n",
    "    \n",
    "    if True:\n",
    "        kf = kfold.split( X ,   y )\n",
    "\n",
    "        best_trees = []\n",
    "        fold_scores = []\n",
    "        \n",
    "        for i, (train_fold, validate) in enumerate(kf):\n",
    "            X_train, X_validate, label_train, label_validate = X[train_fold, :], X[validate, :], y[train_fold], y[validate]\n",
    "            dtrain = lgb.Dataset(X_train, label_train )\n",
    "            dvalid = lgb.Dataset(X_validate, label_validate, reference=dtrain )\n",
    "            bst = lgb.train(params, dtrain, num_boost_round, valid_sets=dvalid , verbose_eval=100,early_stopping_rounds=100)\n",
    "            best_trees.append(bst.best_iteration)\n",
    "            cv_train[validate] += bst.predict(X_validate)\n",
    "            \n",
    "            \n",
    "            score = mean_squared_error( label_validate, cv_train[validate] )\n",
    "            print( score )\n",
    "            fold_scores.append(score)\n",
    "\n",
    "        final_cv_train += cv_train\n",
    "\n",
    "        print(\"cv score:\")\n",
    "        print( mean_squared_error(y, cv_train))\n",
    "        print( \"current score:\", mean_squared_error( y , final_cv_train / (s + 1.)), s+1)\n",
    "        print(fold_scores)\n",
    "        print(best_trees, np.mean(best_trees))\n",
    "\n",
    "        x_score.append(mean_squared_error( y , cv_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
